from pathlib import Path

path = Path("Nodejs.js")
data = path.read_text()
marker = ("streams in node js -> types of streams, readble, diff states of readable streams,  "
          "writable, backpressure , internal buffer of writable, closing writable, states in "
          "wriytbel stream, piping streams, piping using piplines, duplex, transfomr, "
          "passthrough, data streams,, piping and redirection of dtaa streams, opening files in "
          "diff REPL_MODE_SLOPPY, writing to file with file descriptor, handling files using "
          "promises, how browsers use strams -> streams in js")
blank = "\r\n" * 5
old = marker + blank

insert_lines = [
    "### Streams in Node.js (Ultra Detailed)",
    "",
    "#### 1. Why Streams?",
    "- Process massive data incrementally; avoid loading full payload.",
    "- Reduce memory footprint, enable pipelining/compression/encryption on the fly.",
    "- Built atop EventEmitter; integrates with backpressure + Buffer APIs.",
    "",
    "#### 2. Stream Taxonomy",
    "| Type | Direction | Examples |",
    "|------|-----------|----------|",
    "| Readable | source | fs.createReadStream, process.stdin, HTTP request |",
    "| Writable | sink | fs.createWriteStream, process.stdout, HTTP response |",
    "| Duplex | both | net.Socket, tls.TLSSocket |",
    "| Transform | duplex + transform | zlib gzip/brotli, crypto cipher, CSV parser |",
    "| PassThrough | identity | logging / tap for metrics |",
    "| Object Mode | JS objects | set objectMode: true |",
    "",
    "#### 3. Readable States",
    "Paused ↔ Flowing (toggle via pause/resume, pipe, readable event).",
    "",
    "#### 4. Creating Readables",
    "```js",
    "const { Readable } = require('stream');",
    "const fromArray = Readable.from(['a', 'b']);",
    "class Counter extends Readable {",
    "  constructor(max) {",
    "    super();",
    "    this.max = max;",
    "    this.current = 0;",
    "  }",
    "  _read() {",
    "    this.current += 1;",
    "    if (this.current > this.max) this.push(null);",
    "    else this.push(String(this.current));",
    "  }",
    "}",
    "```",
    "",
    "#### 5. Writable Internals & Backpressure",
    "- `highWaterMark` controls internal buffer size (defaults: 16 KB, or 16 objects in object mode).",
    "- `write(chunk)` returns false when buffer full ⇒ wait for `drain` before resuming.",
    "- `end(chunk?)` flushes & emits `finish`; `destroy(err?)` aborts.",
    "```js",
    "if (!writable.write(chunk)) readable.pause();",
    "writable.once('drain', () => readable.resume());",
    "```",
    "",
    "#### 6. `pipe()` and `pipeline()`",
    "```js",
    "fs.createReadStream('input.txt')",
    "  .pipe(zlib.createGzip())",
    "  .pipe(fs.createWriteStream('input.txt.gz'));",
    "```",
    "Use `stream.pipeline` / `stream.promises.pipeline` for automatic error propagation + cleanup.",
    "",
    "#### 7. Transform & Duplex Examples",
    "```js",
    "const { Transform, Duplex } = require('stream');",
    "const upper = new Transform({",
    "  transform(chunk, enc, cb) {",
    "    cb(null, chunk.toString().toUpperCase());",
    "  }",
    "});",
    "class Echo extends Duplex {",
    "  _write(chunk, enc, cb) { this.push(chunk); cb(); }",
    "  _read() {}",
    "}",
    "```",
    "",
    "#### 8. PassThrough Taps",
    "```js",
    "const { PassThrough } = require('stream');",
    "const tap = new PassThrough();",
    "tap.on('data', (chunk) => console.log('len', chunk.length));",
    "source.pipe(tap).pipe(destination);",
    "```",
    "",
    "#### 9. Async Iteration",
    "```js",
    "for await (const chunk of fs.createReadStream('log.txt')) {",
    "  console.log('chunk', chunk.length);",
    "}",
    "```",
    "",
    "#### 10. File Descriptors & Promises",
    "Use `fs.promises.open` + `read` to manage offsets manually when streaming custom layouts.",
    "",
    "#### 11. Browser ↔ Node Streams",
    "Node 18+ provides `Readable.fromWeb` / `Writable.toWeb` to bridge Fetch streams; browsers use `desiredSize` for backpressure.",
    "",
    "#### 12. Error/Close Lifecycle",
    "- Always listen for `error`; otherwise uncaught errors crash process.",
    "- `stream.finished(stream, cb)` (or promise variant) notifies completion or failure.",
    "- `push(null)` signals EOF; `destroy(err)` aborts immediately.",
    "",
    "#### 13. Object Mode & Rate Limiting",
    "Streams can operate in object mode; compose transforms to implement token-bucket throttling.",
    "",
    "#### 14. Practical Pipelines",
    "- File upload (req.pipe(writeStream)).",
    "- HTTP proxy (req → proxyReq, proxyRes → res).",
    "- CSV → JSON pipelines with `csv-parser` + transform + NDJSON writer.",
    "- Compression + encryption chains.",
    "",
    "#### 15. Debugging Tips",
    "- `NODE_DEBUG=stream` to log internals.",
    "- Inspect `readable.readableLength`, `writable.writableLength`.",
    "- Insert `PassThrough` taps to monitor throughput.",
]

insert = "\r\n".join(insert_lines)
new = marker + "\r\n\r\n" + insert + "\r\n\r\n" + blank

if old not in data:
    raise SystemExit("marker block not found")

path.write_text(data.replace(old, new, 1))

